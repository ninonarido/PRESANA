{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninonarido/PRESANA/blob/main/NMT_ATTN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOv8TMFRKKNB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "nGXHKGerM3zg",
        "outputId": "e2790e1b-107e-4c54-bfcb-6c8115b7e432"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-372dee8b-e1ad-4011-b738-30bb7dba93d6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-372dee8b-e1ad-4011-b738-30bb7dba93d6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded =  files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKiYvXz0GV9x"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVZeXVJuKO8T"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = 'sasa.txt' # please set the path according to your system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASVFHeROKVRN",
        "outputId": "f75df069-b5ad-402b-d66f-73cd300f8b73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['TGL\\tBKL',\n",
              " 'Takbo.\\tDaralagan.',\n",
              " 'Sino?\\tSi esay?',\n",
              " 'Yuko!\\tduko!',\n",
              " 'Para!\\tPundo!',\n",
              " 'Kamusta!\\tKamusta!',\n",
              " 'Dali!\\tDali!',\n",
              " 'Sinusubukan ko.\\ttenistingan ko.',\n",
              " 'Ngiti.\\tngirit.',\n",
              " 'Ngumiti ka.\\tmagngirit ka.',\n",
              " 'Sugod!\\tsugod',\n",
              " 'Kainin mo.\\tkakanon mo.',\n",
              " 'Tumakbo siya.\\tnagdalagan sya.',\n",
              " \"Yakapin mo ako.\\tkuguson mo' ko.\",\n",
              " 'Nahulog ako.\\tnauslog ako.',\n",
              " 'Alam ko.\\taram ko.',\n",
              " 'Nagtatrabaho ako.\\tNagtatrabaho ako.',\n",
              " 'Talaga?\\tay iyo?',\n",
              " 'Subukan ito.\\ttestingan ini.',\n",
              " 'Nanalo kami.\\tnaggana kami.',\n",
              " 'Bakit ako?\\ttanu ako?',\n",
              " 'Alis.\\thali.',\n",
              " 'Tawagan mo ako.\\tapudan mo ako.',\n",
              " 'Tawagan mo kami.\\tapudan mo kami.',\n",
              " 'Tawagan niyo kami.\\tapudan nindo kami.',\n",
              " 'Labas!\\tluwas!',\n",
              " 'Lumabas ka!\\tlumuwas ka!',\n",
              " 'Alis.\\thali.',\n",
              " 'Umalis ka!\\tlumuwas ka!',\n",
              " 'Umalis ka.\\tmaghali ka!',\n",
              " 'Umuwi ka.\\tmag-uli ka.',\n",
              " 'Umalis siya.\\tnaghali sya.',\n",
              " 'Tulungan mo ako!\\ttabangan mo ako!',\n",
              " 'Tulungan niyo kami.\\ttabangan nindo kami.',\n",
              " 'Yakapin mo si Tom.\\tKuguson mo si Tom.',\n",
              " 'Sinubukan ko.\\ttenistingan ko.',\n",
              " 'Ako rin.\\tako man.',\n",
              " \"Ipakita sa akin.\\tipahiling sa'ko.\",\n",
              " \"Ipakita mo sa akin.\\tipahiling mo sa'ko.\",\n",
              " \"Ipakita niyo sa akin.\\tipahiling nindo sa'ko.\",\n",
              " 'Itigil iyan.\\tpumundo tabi.',\n",
              " 'Kuhanin mo.\\tkuanon mo.',\n",
              " 'Kuhanin niyo.\\tkuanon nindo.',\n",
              " 'Tumakbo si Tom.\\tnagdalagan si tom',\n",
              " 'Intay.\\thalat baya.',\n",
              " 'Gising!\\tmata na!',\n",
              " 'Gumising ka!\\tmagmata na!',\n",
              " 'Gumising kayo!\\tmagmata na kamo!',\n",
              " 'Natalo kami.\\tnadaog kami.',\n",
              " 'Sinong kumain?\\tsi esay nagkakan?',\n",
              " 'Sinong tumakbo.\\tsi esay nagdalagan.',\n",
              " 'Bakit hindi?\\ttanu ta dae?',\n",
              " 'Tumatakbo ka.\\tNagdalagan ka.',\n",
              " 'Nanalo ka.\\tNanggana ka.',\n",
              " 'Tanungin mo sila.\\thaputon mo sinda.',\n",
              " 'Lumayo ka.\\tmagrayo ka.',\n",
              " 'Maging matapang ka.\\tmaging maisog ka.',\n",
              " 'Tawagin mo si Tom.\\tapudon mo si tom.',\n",
              " 'Tawagan mo si Tom.\\tapudan mo si tom.',\n",
              " 'Hanapin si Tom.\\thanapon si tom.',\n",
              " \"Ayusin mo 'to.\\tpakarayon mo ni.\",\n",
              " \"Ayusin mo ito.\\tpakarayon mo ni'yo.\",\n",
              " 'Pumunta doon.\\tnagduman baga.',\n",
              " 'Ang galing!\\tmatibayon!',\n",
              " 'Hablutin siya.\\tkuanon siya.',\n",
              " 'Magpakasaya kayo.\\tmagpakaugma kamo.',\n",
              " 'Magsaya ka.\\tmagpakaugma ka',\n",
              " 'Magsaya kayo.\\tmag-ugma kamo',\n",
              " 'Tulungan mo si Tom.\\tTabangan mo si tom.',\n",
              " 'Gaano kalalim?\\tguano kararom?',\n",
              " 'Sumang-ayon ako.\\tnaguyon ako.',\n",
              " 'Nakuha ko na.\\tnakua ko na.',\n",
              " 'Nanatili ako.\\tnagtiner ako.',\n",
              " 'Nagintay ako.\\tnaghalat ako.',\n",
              " 'Bumalik na ako.\\tnagbwelta ako.',\n",
              " 'Tapos na ako.\\tTapos na ako.',\n",
              " 'Busog na ako.\\tbasog na ako.',\n",
              " 'Nakauwi na ako.\\tnakauli na ako',\n",
              " 'Nakakatulong.\\tnakakatabang.',\n",
              " 'Ang sakit.\\tmakulugon.',\n",
              " 'Halikan mo si Tom.\\thadukan mo si tom.',\n",
              " 'Tara!\\tmadya na!',\n",
              " 'Iligtas mo si Tom.\\tisalbar mo si tom.',\n",
              " 'Umalis siya.\\tnaghali siya.',\n",
              " 'Upo!\\ttukaw!',\n",
              " 'Umupo ka.\\tmagtukaw ka.',\n",
              " 'Nanalo sila.\\tnaggana sinda.',\n",
              " 'Dumating si Tom.\\tnag-abot si tom.',\n",
              " 'Nahulog si Tom.\\tnauslog si tom.',\n",
              " 'Umalis si Tom.\\tnaghali si tom.',\n",
              " 'Wala na si Tom.\\tmayo na si tom.',\n",
              " 'Nagsinungaling si Tom.\\tnaghambog si tom.',\n",
              " 'Nagsisinungaling si Tom.\\tnaghahambog si tom.',\n",
              " 'Natalo si Tom.\\tnadaog si tom.',\n",
              " 'Nagbayad si Tom.\\tnagbayad si tom.',\n",
              " 'Lumangoy si Tom.\\tLumangoy si Tom.',\n",
              " 'Huli ka na.\\thuri ka na.',\n",
              " 'Subukan ito.\\ttestingan mo ni.',\n",
              " 'Gamitin ito.\\tgamiton ini.',\n",
              " 'Gamitin mo ito.\\tgamiton mo ini.',\n",
              " 'Gamitin niyo ito.\\tgamiton nindo ni.',\n",
              " \"Panoorin ako.\\tdalanon mo'ko.\",\n",
              " 'Panoorin mo ako.\\tdalanon mo ko.',\n",
              " 'Panoorin niyo ako.\\tdalanon nindo ako.',\n",
              " 'Numero uno tayo.\\tnanginginutan kita.',\n",
              " 'Para saan?\\tpara sain?',\n",
              " 'Sinong nahulog?\\tesay an naulog?',\n",
              " 'Sinong lumangoy?\\tesay an lumangoy? ',\n",
              " 'Sino siya?\\tisay yan?',\n",
              " 'Lumilipad ang mga ibon.\\tnaglalayog an mga gamgam.',\n",
              " 'Pagpalain ka.\\tPagpalain ka.',\n",
              " 'Huminahon ka.\\tHuminahon ka.',\n",
              " 'Kumalma ka.\\tKumalma ka.',\n",
              " 'Hulihin si Tom.\\tdakupon si tom.',\n",
              " 'Saluhin mo siya.\\tsaluhon mo siya.',\n",
              " 'Bumalik ka.\\tBumalik ka.',\n",
              " 'Bumalik kayo.\\tmagbalik kami.',\n",
              " 'Halika dito.\\tmadya igdi.',\n",
              " 'Umuwi ka.\\tmaghuli ika.',\n",
              " 'Huwag magsinungaling.\\tdae ka maghambog.',\n",
              " 'Mawalang-galang na.\\ttabi po.',\n",
              " 'Sundan mo ako.\\tmagsunod ka sako.',\n",
              " 'Sundin mo ako.\\tsunodon mo ko.',\n",
              " 'Sundan kami.\\tsunodon kami',\n",
              " 'Sundan mo kami.\\tsunodon mo kami.',\n",
              " 'Sundan niyo kami.\\tsunodon nindo kami.',\n",
              " 'Kalimutan na ito.\\tlingawan na ini.',\n",
              " 'Pumasok ka.\\tmaglaog ka.',\n",
              " 'Matulog na.\\tmagturog na.',\n",
              " 'Huwag humawak.\\tdae ka magkapot.',\n",
              " 'Patawanin mo si Tom.\\tpangiriton mo si tom.',\n",
              " 'Sigurado ako.\\tdae ako nagduduwa-duwa.',\n",
              " 'Tumawa ako.\\tmagngirit ako.',\n",
              " 'Gusto ko.\\tsuno ko.',\n",
              " 'Ginawa ko ito.\\tginibo ko ini.',\n",
              " 'Sinasadya ko.\\ttinutuyo ko.',\n",
              " 'Napansin ko.\\tnarisa ko.',\n",
              " 'Ipinapangako ko.\\tIpinapangako ko.',\n",
              " 'Sumigaw ako.\\tnagsilyak ako.',\n",
              " 'Wala na akong pera.\\tmayo akong kwarta.',\n",
              " 'Wag mong pansinin.\\tbayai lang',\n",
              " 'Mainit ba?\\tmaarasahas?',\n",
              " 'Nasunog.\\tnasulo.',\n",
              " 'Hindi nagtagumpay.\\tdae nagtagumpay.',\n",
              " 'Gumana.\\tnag-gana.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines = open(file_path, encoding='UTF-8').read().strip().split('\\n')\n",
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylb3KR85KYU7",
        "outputId": "12b9ab24-34bb-429d-b954-c9a62cca9521"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "145"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQFnWgYENYfN"
      },
      "outputs": [],
      "source": [
        "\n",
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "remove_digits = str.maketrans('', '', string.digits) # Set of all digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k6ELvQINagZ"
      },
      "outputs": [],
      "source": [
        "def preprocess_tgl_sentence(sent):\n",
        "    '''Function to preprocess tgl sentence'''\n",
        "    sent = sent.lower() # lower casing\n",
        "    sent = re.sub(\"'\", '', sent) # remove the quotation marks if any\n",
        "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
        "    sent = sent.translate(remove_digits) # remove the digits\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(\" +\", \" \", sent) # remove extra spaces\n",
        "    sent = ' ' + sent + ' ' # add  and  tokens\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqE3OD4kNcA2"
      },
      "outputs": [],
      "source": [
        "def preprocess_bkl_sentence(sent):\n",
        "    '''Function to preprocess bkl sentence'''\n",
        "    ssent = sent.lower() # lower casing\n",
        "    sent = re.sub(\"'\", '', sent) # remove the quotation marks if any\n",
        "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
        "    sent = sent.translate(remove_digits) # remove the digits\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(\" +\", \" \", sent) # remove extra spaces\n",
        "    sent = ' ' + sent + ' ' # add  and  tokens\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMfL0CHPNeCu",
        "outputId": "97cbfbc0-f808-4cee-b42f-65e16d324607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[' tgl ', ' BKL '],\n",
              " [' takbo ', ' Daralagan '],\n",
              " [' sino ', ' Si esay '],\n",
              " [' yuko ', ' duko '],\n",
              " [' para ', ' Pundo '],\n",
              " [' kamusta ', ' Kamusta '],\n",
              " [' dali ', ' Dali '],\n",
              " [' sinusubukan ko ', ' tenistingan ko '],\n",
              " [' ngiti ', ' ngirit '],\n",
              " [' ngumiti ka ', ' magngirit ka '],\n",
              " [' sugod ', ' sugod '],\n",
              " [' kainin mo ', ' kakanon mo '],\n",
              " [' tumakbo siya ', ' nagdalagan sya '],\n",
              " [' yakapin mo ako ', ' kuguson mo ko '],\n",
              " [' nahulog ako ', ' nauslog ako '],\n",
              " [' alam ko ', ' aram ko '],\n",
              " [' nagtatrabaho ako ', ' Nagtatrabaho ako '],\n",
              " [' talaga ', ' ay iyo '],\n",
              " [' subukan ito ', ' testingan ini '],\n",
              " [' nanalo kami ', ' naggana kami '],\n",
              " [' bakit ako ', ' tanu ako '],\n",
              " [' alis ', ' hali '],\n",
              " [' tawagan mo ako ', ' apudan mo ako '],\n",
              " [' tawagan mo kami ', ' apudan mo kami '],\n",
              " [' tawagan niyo kami ', ' apudan nindo kami '],\n",
              " [' labas ', ' luwas '],\n",
              " [' lumabas ka ', ' lumuwas ka '],\n",
              " [' alis ', ' hali '],\n",
              " [' umalis ka ', ' lumuwas ka '],\n",
              " [' umalis ka ', ' maghali ka '],\n",
              " [' umuwi ka ', ' maguli ka '],\n",
              " [' umalis siya ', ' naghali sya '],\n",
              " [' tulungan mo ako ', ' tabangan mo ako '],\n",
              " [' tulungan niyo kami ', ' tabangan nindo kami '],\n",
              " [' yakapin mo si tom ', ' Kuguson mo si Tom '],\n",
              " [' sinubukan ko ', ' tenistingan ko '],\n",
              " [' ako rin ', ' ako man '],\n",
              " [' ipakita sa akin ', ' ipahiling sako '],\n",
              " [' ipakita mo sa akin ', ' ipahiling mo sako '],\n",
              " [' ipakita niyo sa akin ', ' ipahiling nindo sako '],\n",
              " [' itigil iyan ', ' pumundo tabi '],\n",
              " [' kuhanin mo ', ' kuanon mo '],\n",
              " [' kuhanin niyo ', ' kuanon nindo '],\n",
              " [' tumakbo si tom ', ' nagdalagan si tom '],\n",
              " [' intay ', ' halat baya '],\n",
              " [' gising ', ' mata na '],\n",
              " [' gumising ka ', ' magmata na '],\n",
              " [' gumising kayo ', ' magmata na kamo '],\n",
              " [' natalo kami ', ' nadaog kami '],\n",
              " [' sinong kumain ', ' si esay nagkakan '],\n",
              " [' sinong tumakbo ', ' si esay nagdalagan '],\n",
              " [' bakit hindi ', ' tanu ta dae '],\n",
              " [' tumatakbo ka ', ' Nagdalagan ka '],\n",
              " [' nanalo ka ', ' Nanggana ka '],\n",
              " [' tanungin mo sila ', ' haputon mo sinda '],\n",
              " [' lumayo ka ', ' magrayo ka '],\n",
              " [' maging matapang ka ', ' maging maisog ka '],\n",
              " [' tawagin mo si tom ', ' apudon mo si tom '],\n",
              " [' tawagan mo si tom ', ' apudan mo si tom '],\n",
              " [' hanapin si tom ', ' hanapon si tom '],\n",
              " [' ayusin mo to ', ' pakarayon mo ni '],\n",
              " [' ayusin mo ito ', ' pakarayon mo niyo '],\n",
              " [' pumunta doon ', ' nagduman baga '],\n",
              " [' ang galing ', ' matibayon '],\n",
              " [' hablutin siya ', ' kuanon siya '],\n",
              " [' magpakasaya kayo ', ' magpakaugma kamo '],\n",
              " [' magsaya ka ', ' magpakaugma ka '],\n",
              " [' magsaya kayo ', ' magugma kamo '],\n",
              " [' tulungan mo si tom ', ' Tabangan mo si tom '],\n",
              " [' gaano kalalim ', ' guano kararom '],\n",
              " [' sumangayon ako ', ' naguyon ako '],\n",
              " [' nakuha ko na ', ' nakua ko na '],\n",
              " [' nanatili ako ', ' nagtiner ako '],\n",
              " [' nagintay ako ', ' naghalat ako '],\n",
              " [' bumalik na ako ', ' nagbwelta ako '],\n",
              " [' tapos na ako ', ' Tapos na ako '],\n",
              " [' busog na ako ', ' basog na ako '],\n",
              " [' nakauwi na ako ', ' nakauli na ako '],\n",
              " [' nakakatulong ', ' nakakatabang '],\n",
              " [' ang sakit ', ' makulugon '],\n",
              " [' halikan mo si tom ', ' hadukan mo si tom '],\n",
              " [' tara ', ' madya na '],\n",
              " [' iligtas mo si tom ', ' isalbar mo si tom '],\n",
              " [' umalis siya ', ' naghali siya '],\n",
              " [' upo ', ' tukaw '],\n",
              " [' umupo ka ', ' magtukaw ka '],\n",
              " [' nanalo sila ', ' naggana sinda '],\n",
              " [' dumating si tom ', ' nagabot si tom '],\n",
              " [' nahulog si tom ', ' nauslog si tom '],\n",
              " [' umalis si tom ', ' naghali si tom '],\n",
              " [' wala na si tom ', ' mayo na si tom '],\n",
              " [' nagsinungaling si tom ', ' naghambog si tom '],\n",
              " [' nagsisinungaling si tom ', ' naghahambog si tom '],\n",
              " [' natalo si tom ', ' nadaog si tom '],\n",
              " [' nagbayad si tom ', ' nagbayad si tom '],\n",
              " [' lumangoy si tom ', ' Lumangoy si Tom '],\n",
              " [' huli ka na ', ' huri ka na '],\n",
              " [' subukan ito ', ' testingan mo ni '],\n",
              " [' gamitin ito ', ' gamiton ini '],\n",
              " [' gamitin mo ito ', ' gamiton mo ini '],\n",
              " [' gamitin niyo ito ', ' gamiton nindo ni '],\n",
              " [' panoorin ako ', ' dalanon moko '],\n",
              " [' panoorin mo ako ', ' dalanon mo ko '],\n",
              " [' panoorin niyo ako ', ' dalanon nindo ako '],\n",
              " [' numero uno tayo ', ' nanginginutan kita '],\n",
              " [' para saan ', ' para sain '],\n",
              " [' sinong nahulog ', ' esay an naulog '],\n",
              " [' sinong lumangoy ', ' esay an lumangoy '],\n",
              " [' sino siya ', ' isay yan '],\n",
              " [' lumilipad ang mga ibon ', ' naglalayog an mga gamgam '],\n",
              " [' pagpalain ka ', ' Pagpalain ka '],\n",
              " [' huminahon ka ', ' Huminahon ka '],\n",
              " [' kumalma ka ', ' Kumalma ka '],\n",
              " [' hulihin si tom ', ' dakupon si tom '],\n",
              " [' saluhin mo siya ', ' saluhon mo siya '],\n",
              " [' bumalik ka ', ' Bumalik ka '],\n",
              " [' bumalik kayo ', ' magbalik kami '],\n",
              " [' halika dito ', ' madya igdi '],\n",
              " [' umuwi ka ', ' maghuli ika '],\n",
              " [' huwag magsinungaling ', ' dae ka maghambog '],\n",
              " [' mawalanggalang na ', ' tabi po '],\n",
              " [' sundan mo ako ', ' magsunod ka sako '],\n",
              " [' sundin mo ako ', ' sunodon mo ko '],\n",
              " [' sundan kami ', ' sunodon kami '],\n",
              " [' sundan mo kami ', ' sunodon mo kami '],\n",
              " [' sundan niyo kami ', ' sunodon nindo kami '],\n",
              " [' kalimutan na ito ', ' lingawan na ini '],\n",
              " [' pumasok ka ', ' maglaog ka '],\n",
              " [' matulog na ', ' magturog na '],\n",
              " [' huwag humawak ', ' dae ka magkapot '],\n",
              " [' patawanin mo si tom ', ' pangiriton mo si tom '],\n",
              " [' sigurado ako ', ' dae ako nagduduwaduwa '],\n",
              " [' tumawa ako ', ' magngirit ako '],\n",
              " [' gusto ko ', ' suno ko '],\n",
              " [' ginawa ko ito ', ' ginibo ko ini '],\n",
              " [' sinasadya ko ', ' tinutuyo ko '],\n",
              " [' napansin ko ', ' narisa ko '],\n",
              " [' ipinapangako ko ', ' Ipinapangako ko '],\n",
              " [' sumigaw ako ', ' nagsilyak ako '],\n",
              " [' wala na akong pera ', ' mayo akong kwarta '],\n",
              " [' wag mong pansinin ', ' bayai lang '],\n",
              " [' mainit ba ', ' maarasahas '],\n",
              " [' nasunog ', ' nasulo '],\n",
              " [' hindi nagtagumpay ', ' dae nagtagumpay '],\n",
              " [' gumana ', ' naggana ']]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate pairs of cleaned English and Marathi sentences\n",
        "sent_pairs = []\n",
        "for line in lines:\n",
        "    sent_pair = []\n",
        "    tgl, bkl = line.split('\\t')\n",
        "    tgl = preprocess_tgl_sentence(tgl)\n",
        "    sent_pair.append(tgl)\n",
        "    bkl = preprocess_bkl_sentence(bkl)\n",
        "    sent_pair.append(bkl)\n",
        "    sent_pairs.append(sent_pair)\n",
        "sent_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8ByAsSRNgZP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        self.word2idx[''] = 0\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1\n",
        "\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CNl3VkrNjjc"
      },
      "outputs": [],
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0p0SNPNNxKG"
      },
      "outputs": [],
      "source": [
        "def load_dataset(pairs, num_examples):\n",
        "    # pairs => already created cleaned input, output pairs\n",
        "\n",
        "    # index language using the class defined above    \n",
        "    inp_lang = LanguageIndex(bkl for bkl, tgl in pairs)\n",
        "    targ_lang = LanguageIndex(tgl for bkl, tgl in pairs)\n",
        "    \n",
        "    # Vectorize the input and target languages\n",
        "    \n",
        "    # English sentences\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in bkl.split(' ')] for bkl, tgl in pairs]\n",
        "    \n",
        "    # Marathi sentences\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in tgl.split(' ')] for bkl, tgl in pairs]\n",
        "    \n",
        "    # Calculate max_length of input and output tensor\n",
        "    # Here, we'll set those to the longest sentence in the dataset\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    \n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meYYifT8N7PW"
      },
      "outputs": [],
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(sent_pairs, len(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOBrtkeLN7mu",
        "outputId": "fba01136-b944-43d0-974f-5366c7d1752d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(130, 130, 15, 15)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1, random_state = 101)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWverXOUN9SF"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 8\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 200\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhVf0ZZ1OAW-"
      },
      "outputs": [],
      "source": [
        "def gru(units):\n",
        "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
        "  # the code automatically does that.\n",
        "    if tf.test.is_gpu_available():\n",
        "        return tf.keras.layers.CuDNNGRU(units, \n",
        "                                        return_sequences=True, \n",
        "                                        return_state=True, \n",
        "                                        recurrent_initializer='glorot_uniform')\n",
        "    else:\n",
        "        return tf.keras.layers.GRU(units, \n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True, \n",
        "                                   recurrent_activation='sigmoid', \n",
        "                                   recurrent_initializer='glorot_uniform')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXQb-lhUOB_v"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size+1, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQNT1jXGODzR"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size+1, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size+1)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TatPnKeUOFaj",
        "outputId": "10b5e03e-9d6f-4460-e723-86bf814c13bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-79aa454bf18b>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kH7qvCROIXJ"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCxU236_OKcR"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNuZC2-FOMCc",
        "outputId": "dfe5c40b-5a06-4811-dc95-51e75c21b179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.0344\n",
            "Epoch 1 Loss 2.4312\n",
            "Time taken for 1 epoch 21.587337970733643 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.1635\n",
            "Epoch 2 Loss 1.9968\n",
            "Time taken for 1 epoch 12.890891551971436 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.1062\n",
            "Epoch 3 Loss 1.8075\n",
            "Time taken for 1 epoch 13.570344686508179 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.5257\n",
            "Epoch 4 Loss 1.6278\n",
            "Time taken for 1 epoch 21.183542490005493 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.4524\n",
            "Epoch 5 Loss 1.4702\n",
            "Time taken for 1 epoch 12.337953329086304 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.2412\n",
            "Epoch 6 Loss 1.3318\n",
            "Time taken for 1 epoch 20.94216775894165 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.2984\n",
            "Epoch 7 Loss 1.2167\n",
            "Time taken for 1 epoch 11.454327583312988 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.0068\n",
            "Epoch 8 Loss 1.1458\n",
            "Time taken for 1 epoch 20.985050678253174 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.8403\n",
            "Epoch 9 Loss 1.0546\n",
            "Time taken for 1 epoch 11.22144365310669 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.9733\n",
            "Epoch 10 Loss 0.9553\n",
            "Time taken for 1 epoch 13.154844999313354 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every epoch\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tIchyOCOPQb"
      },
      "outputs": [],
      "source": [
        "def evaluate(inputs, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    \n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = ''\n",
        "    for i in inputs[0]:\n",
        "        if i == 0:\n",
        "            break\n",
        "        sentence = sentence + inp_lang.idx2word[i] + ' '\n",
        "    sentence = sentence[:-1]\n",
        "    \n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srt2NbimOVGs",
        "outputId": "fe80e7ba-caa8-46f1-cb5f-23752763eef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chart-studio\n",
            "  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     || 64 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n",
            "Collecting retrying>=1.3.3\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (5.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->chart-studio) (8.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n",
            "Building wheels for collected packages: retrying\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11448 sha256=8fc1929caaf24e8e79de4f6bcd2103289cac7f2298d1ee0971b30e1fe45460e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built retrying\n",
            "Installing collected packages: retrying, chart-studio\n",
            "Successfully installed chart-studio-1.1.0 retrying-1.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install chart-studio\n",
        "from chart_studio import plotly\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "\n",
        "def predict_random_val_sentence():\n",
        "    actual_sent = ''\n",
        "    k = np.random.randint(len(input_tensor_val))\n",
        "    random_input = input_tensor_val[k]\n",
        "    random_output = target_tensor_val[k]\n",
        "    random_input = np.expand_dims(random_input,0)\n",
        "    result, sentence, attention_plot = evaluate(random_input, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    for i in random_output:\n",
        "        if i == 0:\n",
        "            break\n",
        "        actual_sent = actual_sent + targ_lang.idx2word[i] + ' '\n",
        "    actual_sent = actual_sent\n",
        "    print('Actual translation: {}'.format(actual_sent))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), 1:len(sentence.split(' '))]\n",
        "    sentence, result = sentence.split(' '), result.split(' ')\n",
        "    sentence = sentence[1:]\n",
        "    result = result[:]\n",
        "    trace = go.Heatmap(z= attention_plot, x = sentence, y = result, colorscale='Reds')\n",
        "    data=[trace]\n",
        "    iplot(data)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "TV4gnaxAOZRi",
        "outputId": "906fe96e-4396-4ee0-ad0d-5c62693e5238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  tulungan mo ako \n",
            "Predicted translation: sunodon mo ko  \n",
            "Actual translation:  tabangan mo ako  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f0bec3ad-77c7-4f43-bf85-4ed0b3d83310\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f0bec3ad-77c7-4f43-bf85-4ed0b3d83310\")) {                    Plotly.newPlot(                        \"f0bec3ad-77c7-4f43-bf85-4ed0b3d83310\",                        [{\"colorscale\":[[0.0,\"rgb(255,245,240)\"],[0.125,\"rgb(254,224,210)\"],[0.25,\"rgb(252,187,161)\"],[0.375,\"rgb(252,146,114)\"],[0.5,\"rgb(251,106,74)\"],[0.625,\"rgb(239,59,44)\"],[0.75,\"rgb(203,24,29)\"],[0.875,\"rgb(165,15,21)\"],[1.0,\"rgb(103,0,13)\"]],\"x\":[\"tulungan\",\"mo\",\"ako\",\"\"],\"y\":[\"sunodon\",\"mo\",\"ko\",\"\",\"\"],\"z\":[[0.02237389236688614,0.0658331885933876,0.1319039762020111,0.19367247819900513],[0.00017613245290704072,0.00174246309325099,0.009034406393766403,0.022874416783452034],[6.9784713559784e-05,0.0006078218575567007,0.0031028713565319777,0.008318072184920311],[8.461800462100655e-05,0.0007332621025852859,0.003635510802268982,0.009557213634252548],[0.0,0.0,0.0,0.0]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f0bec3ad-77c7-4f43-bf85-4ed0b3d83310');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predict_random_val_sentence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHlG8WmxOk1u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}